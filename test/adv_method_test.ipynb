{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from advshotgun import adversary\n",
    "from advshotgun.pretrained_models import Basic_CNN\n",
    "from advshotgun.attacks.white_box import FGSM, randomize_attack\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print(f\"device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classess:10\n",
      "train size:60000\n",
      "test size:10000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "num_classes = mnist_train.classes.__len__()\n",
    "class_logit = torch.eye(num_classes).cuda()\n",
    "\n",
    "print(f\"number of classess:{num_classes}\")\n",
    "print(f\"train size:{mnist_train.__len__()}\")\n",
    "print(f\"test size:{mnist_test.__len__()}\")\n",
    "\n",
    "train_dataloader = DataLoader(mnist_train, batch_size = batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic_CNN(\n",
       "  (conv1_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Basic_CNN.build_Basic_CNN(\"9920.pth.tar\")\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_method = FGSM(eps=0.05)\n",
    "benchmark_method = randomize_attack(eps = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1250it [00:03, 351.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.818399965763092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(mnist_test, batch_size = batch_size, shuffle=False)\n",
    "acc = []\n",
    "for batch_idx, (x, gt) in tqdm(enumerate(test_dataloader)):\n",
    "    x = x.cuda()\n",
    "    gt = gt.cuda()\n",
    "    pred = model(x)\n",
    "    pred_logits = pred.argmax(1)\n",
    "    adv_x = attack_method(x, x, class_logit[gt], model)\n",
    "    pred = model(adv_x)\n",
    "    adv_logits = pred.argmax(1)\n",
    "    acc.append(torch.eq(adv_logits, pred_logits).float().mean())\n",
    "\n",
    "print(f\"accuracy:{torch.stack(acc).mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1250it [00:01, 625.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9842000007629395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test_dataloader = DataLoader(mnist_test, batch_size = batch_size, shuffle=False)\n",
    "acc = []\n",
    "for batch_idx, (x, gt) in tqdm(enumerate(test_dataloader)):\n",
    "    x = x.cuda()\n",
    "    gt = gt.cuda()\n",
    "    pred = model(x)\n",
    "    pred_logits = pred.argmax(1)\n",
    "    adv_x = benchmark_method(x, x, class_logit[gt], model)\n",
    "    pred = model(adv_x)\n",
    "    adv_logits = pred.argmax(1)\n",
    "    acc.append(torch.eq(adv_logits, pred_logits).float().mean())\n",
    "\n",
    "print(f\"accuracy:{torch.stack(acc).mean().item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_advshotgun_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
